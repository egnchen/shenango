diff --git a/include/uapi/linux/bpf.h b/include/uapi/linux/bpf.h
index 1d6085e..64324a2 100644
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@ -2787,6 +2787,12 @@ union bpf_attr {
  * 		The first argument is the context *regs* on which the kprobe
  * 		works.
  *
+ * long bpf_override_regs(struct pt_regs *dst, struct pt_regs *src_from_map)
+ * 	Description
+ * 		Override pt_regs struct(in kernel) with given one.
+ * 	Return
+ * 		0 on success
+ *
  * 		This helper works by setting the PC (program counter)
  * 		to an override function which is run in place of the original
  * 		probed function. This means the probed function is not run at
@@ -5416,6 +5422,7 @@ union bpf_attr {
 	FN(perf_prog_read_value),	\
 	FN(getsockopt),			\
 	FN(override_return),		\
+	FN(override_regs),		\
 	FN(sock_ops_cb_flags_set),	\
 	FN(msg_redirect_map),		\
 	FN(msg_apply_bytes),		\
diff --git a/src/bpf_helper_defs.h b/src/bpf_helper_defs.h
index 56ada5c..638d4f3 100644
--- a/src/bpf_helper_defs.h
+++ b/src/bpf_helper_defs.h
@@ -27,7 +27,6 @@ struct tcp_sock;
 struct tcp_timewait_sock;
 struct tcp_request_sock;
 struct udp6_sock;
-struct unix_sock;
 struct task_struct;
 struct __sk_buff;
 struct sk_msg_md;
@@ -38,10 +37,6 @@ struct inode;
 struct socket;
 struct file;
 struct bpf_timer;
-struct mptcp_sock;
-struct bpf_dynptr;
-struct iphdr;
-struct ipv6hdr;
 
 /*
  * bpf_map_lookup_elem
@@ -195,7 +190,7 @@ static __u32 (*bpf_get_prandom_u32)(void) = (void *) 7;
  * bpf_get_smp_processor_id
  *
  * 	Get the SMP (symmetric multiprocessing) processor id. Note that
- * 	all programs run with migration disabled, which means that the
+ * 	all programs run with preemption disabled, which means that the
  * 	SMP processor id is stable during all the execution of the
  * 	program.
  *
@@ -318,7 +313,7 @@ static long (*bpf_l4_csum_replace)(struct __sk_buff *skb, __u32 offset, __u64 fr
  * 	if the maximum number of tail calls has been reached for this
  * 	chain of programs. This limit is defined in the kernel by the
  * 	macro **MAX_TAIL_CALL_CNT** (not accessible to user space),
- * 	which is currently set to 33.
+ * 	which is currently set to 32.
  *
  * Returns
  * 	0 on success, or a negative error in case of failure.
@@ -356,7 +351,6 @@ static long (*bpf_clone_redirect)(struct __sk_buff *skb, __u32 ifindex, __u64 fl
 /*
  * bpf_get_current_pid_tgid
  *
- * 	Get the current pid and tgid.
  *
  * Returns
  * 	A 64-bit integer containing the current tgid and pid, and
@@ -369,7 +363,6 @@ static __u64 (*bpf_get_current_pid_tgid)(void) = (void *) 14;
 /*
  * bpf_get_current_uid_gid
  *
- * 	Get the current uid and gid.
  *
  * Returns
  * 	A 64-bit integer containing the current GID and UID, and
@@ -925,7 +918,6 @@ static __u32 (*bpf_get_hash_recalc)(struct __sk_buff *skb) = (void *) 34;
 /*
  * bpf_get_current_task
  *
- * 	Get the current task.
  *
  * Returns
  * 	A pointer to the current task struct.
@@ -1005,8 +997,7 @@ static long (*bpf_skb_change_tail)(struct __sk_buff *skb, __u32 len, __u64 flags
  * 	Pull in non-linear data in case the *skb* is non-linear and not
  * 	all of *len* are part of the linear section. Make *len* bytes
  * 	from *skb* readable and writable. If a zero value is passed for
- * 	*len*, then all bytes in the linear part of *skb* will be made
- * 	readable and writable.
+ * 	*len*, then the whole length of the *skb* is pulled.
  *
  * 	This helper is only needed for reading and writing with direct
  * 	packet access.
@@ -1065,8 +1056,6 @@ static __s64 (*bpf_csum_update)(struct __sk_buff *skb, __wsum csum) = (void *) 4
  * 	recalculation the next time the kernel tries to access this
  * 	hash or when the **bpf_get_hash_recalc**\ () helper is called.
  *
- * Returns
- * 	void.
  */
 static void (*bpf_set_hash_invalid)(struct __sk_buff *skb) = (void *) 41;
 
@@ -1166,7 +1155,6 @@ static __u64 (*bpf_get_socket_cookie)(void *ctx) = (void *) 46;
 /*
  * bpf_get_socket_uid
  *
- * 	Get the owner UID of the socked associated to *skb*.
  *
  * Returns
  * 	The owner UID of the socket associated to *skb*. If the socket
@@ -1239,12 +1227,10 @@ static long (*bpf_setsockopt)(void *bpf_socket, int level, int optname, void *op
  * 	There are two supported modes at this time:
  *
  * 	* **BPF_ADJ_ROOM_MAC**: Adjust room at the mac layer
- * 	  (room space is added or removed between the layer 2 and
- * 	  layer 3 headers).
+ * 	  (room space is added or removed below the layer 2 header).
  *
  * 	* **BPF_ADJ_ROOM_NET**: Adjust room at the network layer
- * 	  (room space is added or removed between the layer 3 and
- * 	  layer 4 headers).
+ * 	  (room space is added or removed below the layer 3 header).
  *
  * 	The following flags are supported at this time:
  *
@@ -1506,6 +1492,16 @@ static long (*bpf_getsockopt)(void *bpf_socket, int level, int optname, void *op
  */
 static long (*bpf_override_return)(struct pt_regs *regs, __u64 rc) = (void *) 58;
 
+/*
+ * bpf_override_regs
+ *
+ * 	TODO, you know what it does
+ *
+ * Returns
+ * 	0 on success
+ */
+static long (*bpf_override_regs)(struct pt_regs *dst, struct pt_regs *src_from_map) = (void *) 59;
+
 /*
  * bpf_sock_ops_cb_flags_set
  *
@@ -1552,7 +1548,7 @@ static long (*bpf_override_return)(struct pt_regs *regs, __u64 rc) = (void *) 58
  * 	be set is returned (which comes down to 0 if all bits were set
  * 	as required).
  */
-static long (*bpf_sock_ops_cb_flags_set)(struct bpf_sock_ops *bpf_sock, int argval) = (void *) 59;
+static long (*bpf_sock_ops_cb_flags_set)(struct bpf_sock_ops *bpf_sock, int argval) = (void *) 60;
 
 /*
  * bpf_msg_redirect_map
@@ -1570,7 +1566,7 @@ static long (*bpf_sock_ops_cb_flags_set)(struct bpf_sock_ops *bpf_sock, int argv
  * Returns
  * 	**SK_PASS** on success, or **SK_DROP** on error.
  */
-static long (*bpf_msg_redirect_map)(struct sk_msg_md *msg, void *map, __u32 key, __u64 flags) = (void *) 60;
+static long (*bpf_msg_redirect_map)(struct sk_msg_md *msg, void *map, __u32 key, __u64 flags) = (void *) 61;
 
 /*
  * bpf_msg_apply_bytes
@@ -1608,7 +1604,7 @@ static long (*bpf_msg_redirect_map)(struct sk_msg_md *msg, void *map, __u32 key,
  * Returns
  * 	0
  */
-static long (*bpf_msg_apply_bytes)(struct sk_msg_md *msg, __u32 bytes) = (void *) 61;
+static long (*bpf_msg_apply_bytes)(struct sk_msg_md *msg, __u32 bytes) = (void *) 62;
 
 /*
  * bpf_msg_cork_bytes
@@ -1630,7 +1626,7 @@ static long (*bpf_msg_apply_bytes)(struct sk_msg_md *msg, __u32 bytes) = (void *
  * Returns
  * 	0
  */
-static long (*bpf_msg_cork_bytes)(struct sk_msg_md *msg, __u32 bytes) = (void *) 62;
+static long (*bpf_msg_cork_bytes)(struct sk_msg_md *msg, __u32 bytes) = (void *) 63;
 
 /*
  * bpf_msg_pull_data
@@ -1665,7 +1661,7 @@ static long (*bpf_msg_cork_bytes)(struct sk_msg_md *msg, __u32 bytes) = (void *)
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_msg_pull_data)(struct sk_msg_md *msg, __u32 start, __u32 end, __u64 flags) = (void *) 63;
+static long (*bpf_msg_pull_data)(struct sk_msg_md *msg, __u32 start, __u32 end, __u64 flags) = (void *) 64;
 
 /*
  * bpf_bind
@@ -1687,7 +1683,7 @@ static long (*bpf_msg_pull_data)(struct sk_msg_md *msg, __u32 start, __u32 end,
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_bind)(struct bpf_sock_addr *ctx, struct sockaddr *addr, int addr_len) = (void *) 64;
+static long (*bpf_bind)(struct bpf_sock_addr *ctx, struct sockaddr *addr, int addr_len) = (void *) 65;
 
 /*
  * bpf_xdp_adjust_tail
@@ -1705,7 +1701,7 @@ static long (*bpf_bind)(struct bpf_sock_addr *ctx, struct sockaddr *addr, int ad
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_xdp_adjust_tail)(struct xdp_md *xdp_md, int delta) = (void *) 65;
+static long (*bpf_xdp_adjust_tail)(struct xdp_md *xdp_md, int delta) = (void *) 66;
 
 /*
  * bpf_skb_get_xfrm_state
@@ -1725,7 +1721,7 @@ static long (*bpf_xdp_adjust_tail)(struct xdp_md *xdp_md, int delta) = (void *)
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_skb_get_xfrm_state)(struct __sk_buff *skb, __u32 index, struct bpf_xfrm_state *xfrm_state, __u32 size, __u64 flags) = (void *) 66;
+static long (*bpf_skb_get_xfrm_state)(struct __sk_buff *skb, __u32 index, struct bpf_xfrm_state *xfrm_state, __u32 size, __u64 flags) = (void *) 67;
 
 /*
  * bpf_get_stack
@@ -1744,18 +1740,8 @@ static long (*bpf_skb_get_xfrm_state)(struct __sk_buff *skb, __u32 index, struct
  * 	**BPF_F_USER_STACK**
  * 		Collect a user space stack instead of a kernel stack.
  * 	**BPF_F_USER_BUILD_ID**
- * 		Collect (build_id, file_offset) instead of ips for user
- * 		stack, only valid if **BPF_F_USER_STACK** is also
- * 		specified.
- *
- * 		*file_offset* is an offset relative to the beginning
- * 		of the executable or shared object file backing the vma
- * 		which the *ip* falls in. It is *not* an offset relative
- * 		to that object's base address. Accordingly, it must be
- * 		adjusted by adding (sh_addr - sh_offset), where
- * 		sh_{addr,offset} correspond to the executable section
- * 		containing *file_offset* in the object, for comparisons
- * 		to symbols' st_value to be valid.
+ * 		Collect buildid+offset instead of ips for user stack,
+ * 		only valid if **BPF_F_USER_STACK** is also specified.
  *
  * 	**bpf_get_stack**\ () can collect up to
  * 	**PERF_MAX_STACK_DEPTH** both kernel and user frames, subject
@@ -1769,10 +1755,10 @@ static long (*bpf_skb_get_xfrm_state)(struct __sk_buff *skb, __u32 index, struct
  * 		# sysctl kernel.perf_event_max_stack=<new value>
  *
  * Returns
- * 	The non-negative copied *buf* length equal to or less than
- * 	*size* on success, or a negative error in case of failure.
+ * 	A non-negative value equal to or less than *size* on success,
+ * 	or a negative error in case of failure.
  */
-static long (*bpf_get_stack)(void *ctx, void *buf, __u32 size, __u64 flags) = (void *) 67;
+static long (*bpf_get_stack)(void *ctx, void *buf, __u32 size, __u64 flags) = (void *) 68;
 
 /*
  * bpf_skb_load_bytes_relative
@@ -1798,7 +1784,7 @@ static long (*bpf_get_stack)(void *ctx, void *buf, __u32 size, __u64 flags) = (v
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_skb_load_bytes_relative)(const void *skb, __u32 offset, void *to, __u32 len, __u32 start_header) = (void *) 68;
+static long (*bpf_skb_load_bytes_relative)(const void *skb, __u32 offset, void *to, __u32 len, __u32 start_header) = (void *) 69;
 
 /*
  * bpf_fib_lookup
@@ -1836,7 +1822,7 @@ static long (*bpf_skb_load_bytes_relative)(const void *skb, __u32 offset, void *
  * 	If lookup fails with BPF_FIB_LKUP_RET_FRAG_NEEDED, then the MTU
  * 	was exceeded and output params->mtu_result contains the MTU.
  */
-static long (*bpf_fib_lookup)(void *ctx, struct bpf_fib_lookup *params, int plen, __u32 flags) = (void *) 69;
+static long (*bpf_fib_lookup)(void *ctx, struct bpf_fib_lookup *params, int plen, __u32 flags) = (void *) 70;
 
 /*
  * bpf_sock_hash_update
@@ -1859,7 +1845,7 @@ static long (*bpf_fib_lookup)(void *ctx, struct bpf_fib_lookup *params, int plen
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_sock_hash_update)(struct bpf_sock_ops *skops, void *map, void *key, __u64 flags) = (void *) 70;
+static long (*bpf_sock_hash_update)(struct bpf_sock_ops *skops, void *map, void *key, __u64 flags) = (void *) 71;
 
 /*
  * bpf_msg_redirect_hash
@@ -1877,7 +1863,7 @@ static long (*bpf_sock_hash_update)(struct bpf_sock_ops *skops, void *map, void
  * Returns
  * 	**SK_PASS** on success, or **SK_DROP** on error.
  */
-static long (*bpf_msg_redirect_hash)(struct sk_msg_md *msg, void *map, void *key, __u64 flags) = (void *) 71;
+static long (*bpf_msg_redirect_hash)(struct sk_msg_md *msg, void *map, void *key, __u64 flags) = (void *) 72;
 
 /*
  * bpf_sk_redirect_hash
@@ -1895,7 +1881,7 @@ static long (*bpf_msg_redirect_hash)(struct sk_msg_md *msg, void *map, void *key
  * Returns
  * 	**SK_PASS** on success, or **SK_DROP** on error.
  */
-static long (*bpf_sk_redirect_hash)(struct __sk_buff *skb, void *map, void *key, __u64 flags) = (void *) 72;
+static long (*bpf_sk_redirect_hash)(struct __sk_buff *skb, void *map, void *key, __u64 flags) = (void *) 73;
 
 /*
  * bpf_lwt_push_encap
@@ -1936,7 +1922,7 @@ static long (*bpf_sk_redirect_hash)(struct __sk_buff *skb, void *map, void *key,
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_lwt_push_encap)(struct __sk_buff *skb, __u32 type, void *hdr, __u32 len) = (void *) 73;
+static long (*bpf_lwt_push_encap)(struct __sk_buff *skb, __u32 type, void *hdr, __u32 len) = (void *) 74;
 
 /*
  * bpf_lwt_seg6_store_bytes
@@ -1955,7 +1941,7 @@ static long (*bpf_lwt_push_encap)(struct __sk_buff *skb, __u32 type, void *hdr,
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_lwt_seg6_store_bytes)(struct __sk_buff *skb, __u32 offset, const void *from, __u32 len) = (void *) 74;
+static long (*bpf_lwt_seg6_store_bytes)(struct __sk_buff *skb, __u32 offset, const void *from, __u32 len) = (void *) 75;
 
 /*
  * bpf_lwt_seg6_adjust_srh
@@ -1975,7 +1961,7 @@ static long (*bpf_lwt_seg6_store_bytes)(struct __sk_buff *skb, __u32 offset, con
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_lwt_seg6_adjust_srh)(struct __sk_buff *skb, __u32 offset, __s32 delta) = (void *) 75;
+static long (*bpf_lwt_seg6_adjust_srh)(struct __sk_buff *skb, __u32 offset, __s32 delta) = (void *) 76;
 
 /*
  * bpf_lwt_seg6_action
@@ -2008,7 +1994,7 @@ static long (*bpf_lwt_seg6_adjust_srh)(struct __sk_buff *skb, __u32 offset, __s3
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_lwt_seg6_action)(struct __sk_buff *skb, __u32 action, void *param, __u32 param_len) = (void *) 76;
+static long (*bpf_lwt_seg6_action)(struct __sk_buff *skb, __u32 action, void *param, __u32 param_len) = (void *) 77;
 
 /*
  * bpf_rc_repeat
@@ -2031,7 +2017,7 @@ static long (*bpf_lwt_seg6_action)(struct __sk_buff *skb, __u32 action, void *pa
  * Returns
  * 	0
  */
-static long (*bpf_rc_repeat)(void *ctx) = (void *) 77;
+static long (*bpf_rc_repeat)(void *ctx) = (void *) 78;
 
 /*
  * bpf_rc_keydown
@@ -2061,7 +2047,7 @@ static long (*bpf_rc_repeat)(void *ctx) = (void *) 77;
  * Returns
  * 	0
  */
-static long (*bpf_rc_keydown)(void *ctx, __u32 protocol, __u64 scancode, __u32 toggle) = (void *) 78;
+static long (*bpf_rc_keydown)(void *ctx, __u32 protocol, __u64 scancode, __u32 toggle) = (void *) 79;
 
 /*
  * bpf_skb_cgroup_id
@@ -2081,19 +2067,17 @@ static long (*bpf_rc_keydown)(void *ctx, __u32 protocol, __u64 scancode, __u32 t
  * Returns
  * 	The id is returned or 0 in case the id could not be retrieved.
  */
-static __u64 (*bpf_skb_cgroup_id)(struct __sk_buff *skb) = (void *) 79;
+static __u64 (*bpf_skb_cgroup_id)(struct __sk_buff *skb) = (void *) 80;
 
 /*
  * bpf_get_current_cgroup_id
  *
- * 	Get the current cgroup id based on the cgroup within which
- * 	the current task is running.
  *
  * Returns
  * 	A 64-bit integer containing the current cgroup id based
  * 	on the cgroup within which the current task is running.
  */
-static __u64 (*bpf_get_current_cgroup_id)(void) = (void *) 80;
+static __u64 (*bpf_get_current_cgroup_id)(void) = (void *) 81;
 
 /*
  * bpf_get_local_storage
@@ -2115,7 +2099,7 @@ static __u64 (*bpf_get_current_cgroup_id)(void) = (void *) 80;
  * Returns
  * 	A pointer to the local storage area.
  */
-static void *(*bpf_get_local_storage)(void *map, __u64 flags) = (void *) 81;
+static void *(*bpf_get_local_storage)(void *map, __u64 flags) = (void *) 82;
 
 /*
  * bpf_sk_select_reuseport
@@ -2128,7 +2112,7 @@ static void *(*bpf_get_local_storage)(void *map, __u64 flags) = (void *) 81;
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_sk_select_reuseport)(struct sk_reuseport_md *reuse, void *map, void *key, __u64 flags) = (void *) 82;
+static long (*bpf_sk_select_reuseport)(struct sk_reuseport_md *reuse, void *map, void *key, __u64 flags) = (void *) 83;
 
 /*
  * bpf_skb_ancestor_cgroup_id
@@ -2150,7 +2134,7 @@ static long (*bpf_sk_select_reuseport)(struct sk_reuseport_md *reuse, void *map,
  * Returns
  * 	The id is returned or 0 in case the id could not be retrieved.
  */
-static __u64 (*bpf_skb_ancestor_cgroup_id)(struct __sk_buff *skb, int ancestor_level) = (void *) 83;
+static __u64 (*bpf_skb_ancestor_cgroup_id)(struct __sk_buff *skb, int ancestor_level) = (void *) 84;
 
 /*
  * bpf_sk_lookup_tcp
@@ -2191,7 +2175,7 @@ static __u64 (*bpf_skb_ancestor_cgroup_id)(struct __sk_buff *skb, int ancestor_l
  * 	result is from *reuse*\ **->socks**\ [] using the hash of the
  * 	tuple.
  */
-static struct bpf_sock *(*bpf_sk_lookup_tcp)(void *ctx, struct bpf_sock_tuple *tuple, __u32 tuple_size, __u64 netns, __u64 flags) = (void *) 84;
+static struct bpf_sock *(*bpf_sk_lookup_tcp)(void *ctx, struct bpf_sock_tuple *tuple, __u32 tuple_size, __u64 netns, __u64 flags) = (void *) 85;
 
 /*
  * bpf_sk_lookup_udp
@@ -2232,7 +2216,7 @@ static struct bpf_sock *(*bpf_sk_lookup_tcp)(void *ctx, struct bpf_sock_tuple *t
  * 	result is from *reuse*\ **->socks**\ [] using the hash of the
  * 	tuple.
  */
-static struct bpf_sock *(*bpf_sk_lookup_udp)(void *ctx, struct bpf_sock_tuple *tuple, __u32 tuple_size, __u64 netns, __u64 flags) = (void *) 85;
+static struct bpf_sock *(*bpf_sk_lookup_udp)(void *ctx, struct bpf_sock_tuple *tuple, __u32 tuple_size, __u64 netns, __u64 flags) = (void *) 86;
 
 /*
  * bpf_sk_release
@@ -2244,7 +2228,7 @@ static struct bpf_sock *(*bpf_sk_lookup_udp)(void *ctx, struct bpf_sock_tuple *t
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_sk_release)(void *sock) = (void *) 86;
+static long (*bpf_sk_release)(void *sock) = (void *) 87;
 
 /*
  * bpf_map_push_elem
@@ -2258,7 +2242,7 @@ static long (*bpf_sk_release)(void *sock) = (void *) 86;
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_map_push_elem)(void *map, const void *value, __u64 flags) = (void *) 87;
+static long (*bpf_map_push_elem)(void *map, const void *value, __u64 flags) = (void *) 88;
 
 /*
  * bpf_map_pop_elem
@@ -2268,7 +2252,7 @@ static long (*bpf_map_push_elem)(void *map, const void *value, __u64 flags) = (v
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_map_pop_elem)(void *map, void *value) = (void *) 88;
+static long (*bpf_map_pop_elem)(void *map, void *value) = (void *) 89;
 
 /*
  * bpf_map_peek_elem
@@ -2278,7 +2262,7 @@ static long (*bpf_map_pop_elem)(void *map, void *value) = (void *) 88;
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_map_peek_elem)(void *map, void *value) = (void *) 89;
+static long (*bpf_map_peek_elem)(void *map, void *value) = (void *) 90;
 
 /*
  * bpf_msg_push_data
@@ -2298,7 +2282,7 @@ static long (*bpf_map_peek_elem)(void *map, void *value) = (void *) 89;
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_msg_push_data)(struct sk_msg_md *msg, __u32 start, __u32 len, __u64 flags) = (void *) 90;
+static long (*bpf_msg_push_data)(struct sk_msg_md *msg, __u32 start, __u32 len, __u64 flags) = (void *) 91;
 
 /*
  * bpf_msg_pop_data
@@ -2314,7 +2298,7 @@ static long (*bpf_msg_push_data)(struct sk_msg_md *msg, __u32 start, __u32 len,
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_msg_pop_data)(struct sk_msg_md *msg, __u32 start, __u32 len, __u64 flags) = (void *) 91;
+static long (*bpf_msg_pop_data)(struct sk_msg_md *msg, __u32 start, __u32 len, __u64 flags) = (void *) 92;
 
 /*
  * bpf_rc_pointer_rel
@@ -2332,7 +2316,7 @@ static long (*bpf_msg_pop_data)(struct sk_msg_md *msg, __u32 start, __u32 len, _
  * Returns
  * 	0
  */
-static long (*bpf_rc_pointer_rel)(void *ctx, __s32 rel_x, __s32 rel_y) = (void *) 92;
+static long (*bpf_rc_pointer_rel)(void *ctx, __s32 rel_x, __s32 rel_y) = (void *) 93;
 
 /*
  * bpf_spin_lock
@@ -2384,7 +2368,7 @@ static long (*bpf_rc_pointer_rel)(void *ctx, __s32 rel_x, __s32 rel_y) = (void *
  * Returns
  * 	0
  */
-static long (*bpf_spin_lock)(struct bpf_spin_lock *lock) = (void *) 93;
+static long (*bpf_spin_lock)(struct bpf_spin_lock *lock) = (void *) 94;
 
 /*
  * bpf_spin_unlock
@@ -2395,7 +2379,7 @@ static long (*bpf_spin_lock)(struct bpf_spin_lock *lock) = (void *) 93;
  * Returns
  * 	0
  */
-static long (*bpf_spin_unlock)(struct bpf_spin_lock *lock) = (void *) 94;
+static long (*bpf_spin_unlock)(struct bpf_spin_lock *lock) = (void *) 95;
 
 /*
  * bpf_sk_fullsock
@@ -2407,7 +2391,7 @@ static long (*bpf_spin_unlock)(struct bpf_spin_lock *lock) = (void *) 94;
  * 	A **struct bpf_sock** pointer on success, or **NULL** in
  * 	case of failure.
  */
-static struct bpf_sock *(*bpf_sk_fullsock)(struct bpf_sock *sk) = (void *) 95;
+static struct bpf_sock *(*bpf_sk_fullsock)(struct bpf_sock *sk) = (void *) 96;
 
 /*
  * bpf_tcp_sock
@@ -2419,7 +2403,7 @@ static struct bpf_sock *(*bpf_sk_fullsock)(struct bpf_sock *sk) = (void *) 95;
  * 	A **struct bpf_tcp_sock** pointer on success, or **NULL** in
  * 	case of failure.
  */
-static struct bpf_tcp_sock *(*bpf_tcp_sock)(struct bpf_sock *sk) = (void *) 96;
+static struct bpf_tcp_sock *(*bpf_tcp_sock)(struct bpf_sock *sk) = (void *) 97;
 
 /*
  * bpf_skb_ecn_set_ce
@@ -2433,7 +2417,7 @@ static struct bpf_tcp_sock *(*bpf_tcp_sock)(struct bpf_sock *sk) = (void *) 96;
  * 	1 if the **CE** flag is set (either by the current helper call
  * 	or because it was already present), 0 if it is not set.
  */
-static long (*bpf_skb_ecn_set_ce)(struct __sk_buff *skb) = (void *) 97;
+static long (*bpf_skb_ecn_set_ce)(struct __sk_buff *skb) = (void *) 98;
 
 /*
  * bpf_get_listener_sock
@@ -2445,7 +2429,7 @@ static long (*bpf_skb_ecn_set_ce)(struct __sk_buff *skb) = (void *) 97;
  * 	A **struct bpf_sock** pointer on success, or **NULL** in
  * 	case of failure.
  */
-static struct bpf_sock *(*bpf_get_listener_sock)(struct bpf_sock *sk) = (void *) 98;
+static struct bpf_sock *(*bpf_get_listener_sock)(struct bpf_sock *sk) = (void *) 99;
 
 /*
  * bpf_skc_lookup_tcp
@@ -2468,7 +2452,7 @@ static struct bpf_sock *(*bpf_get_listener_sock)(struct bpf_sock *sk) = (void *)
  * 	result is from *reuse*\ **->socks**\ [] using the hash of the
  * 	tuple.
  */
-static struct bpf_sock *(*bpf_skc_lookup_tcp)(void *ctx, struct bpf_sock_tuple *tuple, __u32 tuple_size, __u64 netns, __u64 flags) = (void *) 99;
+static struct bpf_sock *(*bpf_skc_lookup_tcp)(void *ctx, struct bpf_sock_tuple *tuple, __u32 tuple_size, __u64 netns, __u64 flags) = (void *) 100;
 
 /*
  * bpf_tcp_check_syncookie
@@ -2478,17 +2462,16 @@ static struct bpf_sock *(*bpf_skc_lookup_tcp)(void *ctx, struct bpf_sock_tuple *
  *
  * 	*iph* points to the start of the IPv4 or IPv6 header, while
  * 	*iph_len* contains **sizeof**\ (**struct iphdr**) or
- * 	**sizeof**\ (**struct ipv6hdr**).
+ * 	**sizeof**\ (**struct ip6hdr**).
  *
  * 	*th* points to the start of the TCP header, while *th_len*
- * 	contains the length of the TCP header (at least
- * 	**sizeof**\ (**struct tcphdr**)).
+ * 	contains **sizeof**\ (**struct tcphdr**).
  *
  * Returns
  * 	0 if *iph* and *th* are a valid SYN cookie ACK, or a negative
  * 	error otherwise.
  */
-static long (*bpf_tcp_check_syncookie)(void *sk, void *iph, __u32 iph_len, struct tcphdr *th, __u32 th_len) = (void *) 100;
+static long (*bpf_tcp_check_syncookie)(void *sk, void *iph, __u32 iph_len, struct tcphdr *th, __u32 th_len) = (void *) 101;
 
 /*
  * bpf_sysctl_get_name
@@ -2508,7 +2491,7 @@ static long (*bpf_tcp_check_syncookie)(void *sk, void *iph, __u32 iph_len, struc
  * 	**-E2BIG** if the buffer wasn't big enough (*buf* will contain
  * 	truncated name in this case).
  */
-static long (*bpf_sysctl_get_name)(struct bpf_sysctl *ctx, char *buf, unsigned long buf_len, __u64 flags) = (void *) 101;
+static long (*bpf_sysctl_get_name)(struct bpf_sysctl *ctx, char *buf, unsigned long buf_len, __u64 flags) = (void *) 102;
 
 /*
  * bpf_sysctl_get_current_value
@@ -2531,7 +2514,7 @@ static long (*bpf_sysctl_get_name)(struct bpf_sysctl *ctx, char *buf, unsigned l
  * 	**-EINVAL** if current value was unavailable, e.g. because
  * 	sysctl is uninitialized and read returns -EIO for it.
  */
-static long (*bpf_sysctl_get_current_value)(struct bpf_sysctl *ctx, char *buf, unsigned long buf_len) = (void *) 102;
+static long (*bpf_sysctl_get_current_value)(struct bpf_sysctl *ctx, char *buf, unsigned long buf_len) = (void *) 103;
 
 /*
  * bpf_sysctl_get_new_value
@@ -2552,7 +2535,7 @@ static long (*bpf_sysctl_get_current_value)(struct bpf_sysctl *ctx, char *buf, u
  *
  * 	**-EINVAL** if sysctl is being read.
  */
-static long (*bpf_sysctl_get_new_value)(struct bpf_sysctl *ctx, char *buf, unsigned long buf_len) = (void *) 103;
+static long (*bpf_sysctl_get_new_value)(struct bpf_sysctl *ctx, char *buf, unsigned long buf_len) = (void *) 104;
 
 /*
  * bpf_sysctl_set_new_value
@@ -2573,7 +2556,7 @@ static long (*bpf_sysctl_get_new_value)(struct bpf_sysctl *ctx, char *buf, unsig
  *
  * 	**-EINVAL** if sysctl is being read.
  */
-static long (*bpf_sysctl_set_new_value)(struct bpf_sysctl *ctx, const char *buf, unsigned long buf_len) = (void *) 104;
+static long (*bpf_sysctl_set_new_value)(struct bpf_sysctl *ctx, const char *buf, unsigned long buf_len) = (void *) 105;
 
 /*
  * bpf_strtol
@@ -2601,7 +2584,7 @@ static long (*bpf_sysctl_set_new_value)(struct bpf_sysctl *ctx, const char *buf,
  *
  * 	**-ERANGE** if resulting value was out of range.
  */
-static long (*bpf_strtol)(const char *buf, unsigned long buf_len, __u64 flags, long *res) = (void *) 105;
+static long (*bpf_strtol)(const char *buf, unsigned long buf_len, __u64 flags, long *res) = (void *) 106;
 
 /*
  * bpf_strtoul
@@ -2628,7 +2611,7 @@ static long (*bpf_strtol)(const char *buf, unsigned long buf_len, __u64 flags, l
  *
  * 	**-ERANGE** if resulting value was out of range.
  */
-static long (*bpf_strtoul)(const char *buf, unsigned long buf_len, __u64 flags, unsigned long *res) = (void *) 106;
+static long (*bpf_strtoul)(const char *buf, unsigned long buf_len, __u64 flags, unsigned long *res) = (void *) 107;
 
 /*
  * bpf_sk_storage_get
@@ -2663,7 +2646,7 @@ static long (*bpf_strtoul)(const char *buf, unsigned long buf_len, __u64 flags,
  * 	**NULL** if not found or there was an error in adding
  * 	a new bpf-local-storage.
  */
-static void *(*bpf_sk_storage_get)(void *map, void *sk, void *value, __u64 flags) = (void *) 107;
+static void *(*bpf_sk_storage_get)(void *map, void *sk, void *value, __u64 flags) = (void *) 108;
 
 /*
  * bpf_sk_storage_delete
@@ -2676,7 +2659,7 @@ static void *(*bpf_sk_storage_get)(void *map, void *sk, void *value, __u64 flags
  * 	**-ENOENT** if the bpf-local-storage cannot be found.
  * 	**-EINVAL** if sk is not a fullsock (e.g. a request_sock).
  */
-static long (*bpf_sk_storage_delete)(void *map, void *sk) = (void *) 108;
+static long (*bpf_sk_storage_delete)(void *map, void *sk) = (void *) 109;
 
 /*
  * bpf_send_signal
@@ -2695,7 +2678,7 @@ static long (*bpf_sk_storage_delete)(void *map, void *sk) = (void *) 108;
  *
  * 	**-EAGAIN** if bpf program can try again.
  */
-static long (*bpf_send_signal)(__u32 sig) = (void *) 109;
+static long (*bpf_send_signal)(__u32 sig) = (void *) 110;
 
 /*
  * bpf_tcp_gen_syncookie
@@ -2705,11 +2688,10 @@ static long (*bpf_send_signal)(__u32 sig) = (void *) 109;
  *
  * 	*iph* points to the start of the IPv4 or IPv6 header, while
  * 	*iph_len* contains **sizeof**\ (**struct iphdr**) or
- * 	**sizeof**\ (**struct ipv6hdr**).
+ * 	**sizeof**\ (**struct ip6hdr**).
  *
  * 	*th* points to the start of the TCP header, while *th_len*
- * 	contains the length of the TCP header with options (at least
- * 	**sizeof**\ (**struct tcphdr**)).
+ * 	contains the length of the TCP header.
  *
  * Returns
  * 	On success, lower 32 bits hold the generated SYN cookie in
@@ -2726,7 +2708,7 @@ static long (*bpf_send_signal)(__u32 sig) = (void *) 109;
  *
  * 	**-EPROTONOSUPPORT** IP packet version is not 4 or 6
  */
-static __s64 (*bpf_tcp_gen_syncookie)(void *sk, void *iph, __u32 iph_len, struct tcphdr *th, __u32 th_len) = (void *) 110;
+static __s64 (*bpf_tcp_gen_syncookie)(void *sk, void *iph, __u32 iph_len, struct tcphdr *th, __u32 th_len) = (void *) 111;
 
 /*
  * bpf_skb_output
@@ -2754,7 +2736,7 @@ static __s64 (*bpf_tcp_gen_syncookie)(void *sk, void *iph, __u32 iph_len, struct
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_skb_output)(void *ctx, void *map, __u64 flags, void *data, __u64 size) = (void *) 111;
+static long (*bpf_skb_output)(void *ctx, void *map, __u64 flags, void *data, __u64 size) = (void *) 112;
 
 /*
  * bpf_probe_read_user
@@ -2765,7 +2747,7 @@ static long (*bpf_skb_output)(void *ctx, void *map, __u64 flags, void *data, __u
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_probe_read_user)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 112;
+static long (*bpf_probe_read_user)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 113;
 
 /*
  * bpf_probe_read_kernel
@@ -2776,7 +2758,7 @@ static long (*bpf_probe_read_user)(void *dst, __u32 size, const void *unsafe_ptr
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_probe_read_kernel)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 113;
+static long (*bpf_probe_read_kernel)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 114;
 
 /*
  * bpf_probe_read_user_str
@@ -2824,7 +2806,7 @@ static long (*bpf_probe_read_kernel)(void *dst, __u32 size, const void *unsafe_p
  * 	including the trailing NUL character. On error, a negative
  * 	value.
  */
-static long (*bpf_probe_read_user_str)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 114;
+static long (*bpf_probe_read_user_str)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 115;
 
 /*
  * bpf_probe_read_kernel_str
@@ -2836,7 +2818,7 @@ static long (*bpf_probe_read_user_str)(void *dst, __u32 size, const void *unsafe
  * 	On success, the strictly positive length of the string, including
  * 	the trailing NUL character. On error, a negative value.
  */
-static long (*bpf_probe_read_kernel_str)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 115;
+static long (*bpf_probe_read_kernel_str)(void *dst, __u32 size, const void *unsafe_ptr) = (void *) 116;
 
 /*
  * bpf_tcp_send_ack
@@ -2847,7 +2829,7 @@ static long (*bpf_probe_read_kernel_str)(void *dst, __u32 size, const void *unsa
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_tcp_send_ack)(void *tp, __u32 rcv_nxt) = (void *) 116;
+static long (*bpf_tcp_send_ack)(void *tp, __u32 rcv_nxt) = (void *) 117;
 
 /*
  * bpf_send_signal_thread
@@ -2865,7 +2847,7 @@ static long (*bpf_tcp_send_ack)(void *tp, __u32 rcv_nxt) = (void *) 116;
  *
  * 	**-EAGAIN** if bpf program can try again.
  */
-static long (*bpf_send_signal_thread)(__u32 sig) = (void *) 117;
+static long (*bpf_send_signal_thread)(__u32 sig) = (void *) 118;
 
 /*
  * bpf_jiffies64
@@ -2875,7 +2857,7 @@ static long (*bpf_send_signal_thread)(__u32 sig) = (void *) 117;
  * Returns
  * 	The 64 bit jiffies
  */
-static __u64 (*bpf_jiffies64)(void) = (void *) 118;
+static __u64 (*bpf_jiffies64)(void) = (void *) 119;
 
 /*
  * bpf_read_branch_records
@@ -2898,7 +2880,7 @@ static __u64 (*bpf_jiffies64)(void) = (void *) 118;
  *
  * 	**-ENOENT** if architecture does not support branch records.
  */
-static long (*bpf_read_branch_records)(struct bpf_perf_event_data *ctx, void *buf, __u32 size, __u64 flags) = (void *) 119;
+static long (*bpf_read_branch_records)(struct bpf_perf_event_data *ctx, void *buf, __u32 size, __u64 flags) = (void *) 120;
 
 /*
  * bpf_get_ns_current_pid_tgid
@@ -2914,7 +2896,7 @@ static long (*bpf_read_branch_records)(struct bpf_perf_event_data *ctx, void *bu
  *
  * 	**-ENOENT** if pidns does not exists for the current task.
  */
-static long (*bpf_get_ns_current_pid_tgid)(__u64 dev, __u64 ino, struct bpf_pidns_info *nsdata, __u32 size) = (void *) 120;
+static long (*bpf_get_ns_current_pid_tgid)(__u64 dev, __u64 ino, struct bpf_pidns_info *nsdata, __u32 size) = (void *) 121;
 
 /*
  * bpf_xdp_output
@@ -2942,7 +2924,7 @@ static long (*bpf_get_ns_current_pid_tgid)(__u64 dev, __u64 ino, struct bpf_pidn
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_xdp_output)(void *ctx, void *map, __u64 flags, void *data, __u64 size) = (void *) 121;
+static long (*bpf_xdp_output)(void *ctx, void *map, __u64 flags, void *data, __u64 size) = (void *) 122;
 
 /*
  * bpf_get_netns_cookie
@@ -2959,7 +2941,7 @@ static long (*bpf_xdp_output)(void *ctx, void *map, __u64 flags, void *data, __u
  * Returns
  * 	A 8-byte long opaque number.
  */
-static __u64 (*bpf_get_netns_cookie)(void *ctx) = (void *) 122;
+static __u64 (*bpf_get_netns_cookie)(void *ctx) = (void *) 123;
 
 /*
  * bpf_get_current_ancestor_cgroup_id
@@ -2981,7 +2963,7 @@ static __u64 (*bpf_get_netns_cookie)(void *ctx) = (void *) 122;
  * Returns
  * 	The id is returned or 0 in case the id could not be retrieved.
  */
-static __u64 (*bpf_get_current_ancestor_cgroup_id)(int ancestor_level) = (void *) 123;
+static __u64 (*bpf_get_current_ancestor_cgroup_id)(int ancestor_level) = (void *) 124;
 
 /*
  * bpf_sk_assign
@@ -3016,7 +2998,7 @@ static __u64 (*bpf_get_current_ancestor_cgroup_id)(int ancestor_level) = (void *
  * 	**-ESOCKTNOSUPPORT** if the socket type is not supported
  * 	(reuseport).
  */
-static long (*bpf_sk_assign)(void *ctx, void *sk, __u64 flags) = (void *) 124;
+static long (*bpf_sk_assign)(void *ctx, void *sk, __u64 flags) = (void *) 125;
 
 /*
  * bpf_ktime_get_boot_ns
@@ -3028,7 +3010,7 @@ static long (*bpf_sk_assign)(void *ctx, void *sk, __u64 flags) = (void *) 124;
  * Returns
  * 	Current *ktime*.
  */
-static __u64 (*bpf_ktime_get_boot_ns)(void) = (void *) 125;
+static __u64 (*bpf_ktime_get_boot_ns)(void) = (void *) 126;
 
 /*
  * bpf_seq_printf
@@ -3040,7 +3022,7 @@ static __u64 (*bpf_ktime_get_boot_ns)(void) = (void *) 125;
  * 	arguments. The *data* are a **u64** array and corresponding format string
  * 	values are stored in the array. For strings and pointers where pointees
  * 	are accessed, only the pointer values are stored in the *data* array.
- * 	The *data_len* is the size of *data* in bytes - must be a multiple of 8.
+ * 	The *data_len* is the size of *data* in bytes.
  *
  * 	Formats **%s**, **%p{i,I}{4,6}** requires to read kernel memory.
  * 	Reading kernel memory may fail due to either invalid address or
@@ -3061,7 +3043,7 @@ static __u64 (*bpf_ktime_get_boot_ns)(void) = (void *) 125;
  *
  * 	**-EOVERFLOW** if an overflow happened: The same object will be tried again.
  */
-static long (*bpf_seq_printf)(struct seq_file *m, const char *fmt, __u32 fmt_size, const void *data, __u32 data_len) = (void *) 126;
+static long (*bpf_seq_printf)(struct seq_file *m, const char *fmt, __u32 fmt_size, const void *data, __u32 data_len) = (void *) 127;
 
 /*
  * bpf_seq_write
@@ -3075,7 +3057,7 @@ static long (*bpf_seq_printf)(struct seq_file *m, const char *fmt, __u32 fmt_siz
  *
  * 	**-EOVERFLOW** if an overflow happened: The same object will be tried again.
  */
-static long (*bpf_seq_write)(struct seq_file *m, const void *data, __u32 len) = (void *) 127;
+static long (*bpf_seq_write)(struct seq_file *m, const void *data, __u32 len) = (void *) 128;
 
 /*
  * bpf_sk_cgroup_id
@@ -3093,7 +3075,7 @@ static long (*bpf_seq_write)(struct seq_file *m, const void *data, __u32 len) =
  * Returns
  * 	The id is returned or 0 in case the id could not be retrieved.
  */
-static __u64 (*bpf_sk_cgroup_id)(void *sk) = (void *) 128;
+static __u64 (*bpf_sk_cgroup_id)(void *sk) = (void *) 129;
 
 /*
  * bpf_sk_ancestor_cgroup_id
@@ -3115,7 +3097,7 @@ static __u64 (*bpf_sk_cgroup_id)(void *sk) = (void *) 128;
  * Returns
  * 	The id is returned or 0 in case the id could not be retrieved.
  */
-static __u64 (*bpf_sk_ancestor_cgroup_id)(void *sk, int ancestor_level) = (void *) 129;
+static __u64 (*bpf_sk_ancestor_cgroup_id)(void *sk, int ancestor_level) = (void *) 130;
 
 /*
  * bpf_ringbuf_output
@@ -3136,7 +3118,7 @@ static __u64 (*bpf_sk_ancestor_cgroup_id)(void *sk, int ancestor_level) = (void
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_ringbuf_output)(void *ringbuf, void *data, __u64 size, __u64 flags) = (void *) 130;
+static long (*bpf_ringbuf_output)(void *ringbuf, void *data, __u64 size, __u64 flags) = (void *) 131;
 
 /*
  * bpf_ringbuf_reserve
@@ -3148,7 +3130,7 @@ static long (*bpf_ringbuf_output)(void *ringbuf, void *data, __u64 size, __u64 f
  * 	Valid pointer with *size* bytes of memory available; NULL,
  * 	otherwise.
  */
-static void *(*bpf_ringbuf_reserve)(void *ringbuf, __u64 size, __u64 flags) = (void *) 131;
+static void *(*bpf_ringbuf_reserve)(void *ringbuf, __u64 size, __u64 flags) = (void *) 132;
 
 /*
  * bpf_ringbuf_submit
@@ -3166,7 +3148,7 @@ static void *(*bpf_ringbuf_reserve)(void *ringbuf, __u64 size, __u64 flags) = (v
  * Returns
  * 	Nothing. Always succeeds.
  */
-static void (*bpf_ringbuf_submit)(void *data, __u64 flags) = (void *) 132;
+static void (*bpf_ringbuf_submit)(void *data, __u64 flags) = (void *) 133;
 
 /*
  * bpf_ringbuf_discard
@@ -3184,7 +3166,7 @@ static void (*bpf_ringbuf_submit)(void *data, __u64 flags) = (void *) 132;
  * Returns
  * 	Nothing. Always succeeds.
  */
-static void (*bpf_ringbuf_discard)(void *data, __u64 flags) = (void *) 133;
+static void (*bpf_ringbuf_discard)(void *data, __u64 flags) = (void *) 134;
 
 /*
  * bpf_ringbuf_query
@@ -3205,7 +3187,7 @@ static void (*bpf_ringbuf_discard)(void *data, __u64 flags) = (void *) 133;
  * Returns
  * 	Requested value, or 0, if *flags* are not recognized.
  */
-static __u64 (*bpf_ringbuf_query)(void *ringbuf, __u64 flags) = (void *) 134;
+static __u64 (*bpf_ringbuf_query)(void *ringbuf, __u64 flags) = (void *) 135;
 
 /*
  * bpf_csum_level
@@ -3241,7 +3223,7 @@ static __u64 (*bpf_ringbuf_query)(void *ringbuf, __u64 flags) = (void *) 134;
  * 	is returned or the error code -EACCES in case the skb is not
  * 	subject to CHECKSUM_UNNECESSARY.
  */
-static long (*bpf_csum_level)(struct __sk_buff *skb, __u64 level) = (void *) 135;
+static long (*bpf_csum_level)(struct __sk_buff *skb, __u64 level) = (void *) 136;
 
 /*
  * bpf_skc_to_tcp6_sock
@@ -3251,7 +3233,7 @@ static long (*bpf_csum_level)(struct __sk_buff *skb, __u64 level) = (void *) 135
  * Returns
  * 	*sk* if casting is valid, or **NULL** otherwise.
  */
-static struct tcp6_sock *(*bpf_skc_to_tcp6_sock)(void *sk) = (void *) 136;
+static struct tcp6_sock *(*bpf_skc_to_tcp6_sock)(void *sk) = (void *) 137;
 
 /*
  * bpf_skc_to_tcp_sock
@@ -3261,7 +3243,7 @@ static struct tcp6_sock *(*bpf_skc_to_tcp6_sock)(void *sk) = (void *) 136;
  * Returns
  * 	*sk* if casting is valid, or **NULL** otherwise.
  */
-static struct tcp_sock *(*bpf_skc_to_tcp_sock)(void *sk) = (void *) 137;
+static struct tcp_sock *(*bpf_skc_to_tcp_sock)(void *sk) = (void *) 138;
 
 /*
  * bpf_skc_to_tcp_timewait_sock
@@ -3271,7 +3253,7 @@ static struct tcp_sock *(*bpf_skc_to_tcp_sock)(void *sk) = (void *) 137;
  * Returns
  * 	*sk* if casting is valid, or **NULL** otherwise.
  */
-static struct tcp_timewait_sock *(*bpf_skc_to_tcp_timewait_sock)(void *sk) = (void *) 138;
+static struct tcp_timewait_sock *(*bpf_skc_to_tcp_timewait_sock)(void *sk) = (void *) 139;
 
 /*
  * bpf_skc_to_tcp_request_sock
@@ -3281,7 +3263,7 @@ static struct tcp_timewait_sock *(*bpf_skc_to_tcp_timewait_sock)(void *sk) = (vo
  * Returns
  * 	*sk* if casting is valid, or **NULL** otherwise.
  */
-static struct tcp_request_sock *(*bpf_skc_to_tcp_request_sock)(void *sk) = (void *) 139;
+static struct tcp_request_sock *(*bpf_skc_to_tcp_request_sock)(void *sk) = (void *) 140;
 
 /*
  * bpf_skc_to_udp6_sock
@@ -3291,7 +3273,7 @@ static struct tcp_request_sock *(*bpf_skc_to_tcp_request_sock)(void *sk) = (void
  * Returns
  * 	*sk* if casting is valid, or **NULL** otherwise.
  */
-static struct udp6_sock *(*bpf_skc_to_udp6_sock)(void *sk) = (void *) 140;
+static struct udp6_sock *(*bpf_skc_to_udp6_sock)(void *sk) = (void *) 141;
 
 /*
  * bpf_get_task_stack
@@ -3324,10 +3306,10 @@ static struct udp6_sock *(*bpf_skc_to_udp6_sock)(void *sk) = (void *) 140;
  * 		# sysctl kernel.perf_event_max_stack=<new value>
  *
  * Returns
- * 	The non-negative copied *buf* length equal to or less than
- * 	*size* on success, or a negative error in case of failure.
+ * 	A non-negative value equal to or less than *size* on success,
+ * 	or a negative error in case of failure.
  */
-static long (*bpf_get_task_stack)(struct task_struct *task, void *buf, __u32 size, __u64 flags) = (void *) 141;
+static long (*bpf_get_task_stack)(struct task_struct *task, void *buf, __u32 size, __u64 flags) = (void *) 142;
 
 /*
  * bpf_load_hdr_opt
@@ -3394,7 +3376,7 @@ static long (*bpf_get_task_stack)(struct task_struct *task, void *buf, __u32 siz
  * 	**-EPERM** if the helper cannot be used under the current
  * 	*skops*\ **->op**.
  */
-static long (*bpf_load_hdr_opt)(struct bpf_sock_ops *skops, void *searchby_res, __u32 len, __u64 flags) = (void *) 142;
+static long (*bpf_load_hdr_opt)(struct bpf_sock_ops *skops, void *searchby_res, __u32 len, __u64 flags) = (void *) 143;
 
 /*
  * bpf_store_hdr_opt
@@ -3431,7 +3413,7 @@ static long (*bpf_load_hdr_opt)(struct bpf_sock_ops *skops, void *searchby_res,
  * 	**-EPERM** if the helper cannot be used under the current
  * 	*skops*\ **->op**.
  */
-static long (*bpf_store_hdr_opt)(struct bpf_sock_ops *skops, const void *from, __u32 len, __u64 flags) = (void *) 143;
+static long (*bpf_store_hdr_opt)(struct bpf_sock_ops *skops, const void *from, __u32 len, __u64 flags) = (void *) 144;
 
 /*
  * bpf_reserve_hdr_opt
@@ -3457,7 +3439,7 @@ static long (*bpf_store_hdr_opt)(struct bpf_sock_ops *skops, const void *from, _
  * 	**-EPERM** if the helper cannot be used under the current
  * 	*skops*\ **->op**.
  */
-static long (*bpf_reserve_hdr_opt)(struct bpf_sock_ops *skops, __u32 len, __u64 flags) = (void *) 144;
+static long (*bpf_reserve_hdr_opt)(struct bpf_sock_ops *skops, __u32 len, __u64 flags) = (void *) 145;
 
 /*
  * bpf_inode_storage_get
@@ -3489,7 +3471,7 @@ static long (*bpf_reserve_hdr_opt)(struct bpf_sock_ops *skops, __u32 len, __u64
  * 	**NULL** if not found or there was an error in adding
  * 	a new bpf_local_storage.
  */
-static void *(*bpf_inode_storage_get)(void *map, void *inode, void *value, __u64 flags) = (void *) 145;
+static void *(*bpf_inode_storage_get)(void *map, void *inode, void *value, __u64 flags) = (void *) 146;
 
 /*
  * bpf_inode_storage_delete
@@ -3501,7 +3483,7 @@ static void *(*bpf_inode_storage_get)(void *map, void *inode, void *value, __u64
  *
  * 	**-ENOENT** if the bpf_local_storage cannot be found.
  */
-static int (*bpf_inode_storage_delete)(void *map, void *inode) = (void *) 146;
+static int (*bpf_inode_storage_delete)(void *map, void *inode) = (void *) 147;
 
 /*
  * bpf_d_path
@@ -3517,7 +3499,7 @@ static int (*bpf_inode_storage_delete)(void *map, void *inode) = (void *) 146;
  * 	including the trailing NUL character. On error, a negative
  * 	value.
  */
-static long (*bpf_d_path)(struct path *path, char *buf, __u32 sz) = (void *) 147;
+static long (*bpf_d_path)(struct path *path, char *buf, __u32 sz) = (void *) 148;
 
 /*
  * bpf_copy_from_user
@@ -3528,7 +3510,7 @@ static long (*bpf_d_path)(struct path *path, char *buf, __u32 sz) = (void *) 147
  * Returns
  * 	0 on success, or a negative error in case of failure.
  */
-static long (*bpf_copy_from_user)(void *dst, __u32 size, const void *user_ptr) = (void *) 148;
+static long (*bpf_copy_from_user)(void *dst, __u32 size, const void *user_ptr) = (void *) 149;
 
 /*
  * bpf_snprintf_btf
@@ -3568,7 +3550,7 @@ static long (*bpf_copy_from_user)(void *dst, __u32 size, const void *user_ptr) =
  * 	written if output had to be truncated due to string size),
  * 	or a negative error in cases of failure.
  */
-static long (*bpf_snprintf_btf)(char *str, __u32 str_size, struct btf_ptr *ptr, __u32 btf_ptr_size, __u64 flags) = (void *) 149;
+static long (*bpf_snprintf_btf)(char *str, __u32 str_size, struct btf_ptr *ptr, __u32 btf_ptr_size, __u64 flags) = (void *) 150;
 
 /*
  * bpf_seq_printf_btf
@@ -3580,7 +3562,7 @@ static long (*bpf_snprintf_btf)(char *str, __u32 str_size, struct btf_ptr *ptr,
  * Returns
  * 	0 on success or a negative error in case of failure.
  */
-static long (*bpf_seq_printf_btf)(struct seq_file *m, struct btf_ptr *ptr, __u32 ptr_size, __u64 flags) = (void *) 150;
+static long (*bpf_seq_printf_btf)(struct seq_file *m, struct btf_ptr *ptr, __u32 ptr_size, __u64 flags) = (void *) 151;
 
 /*
  * bpf_skb_cgroup_classid
@@ -3593,7 +3575,7 @@ static long (*bpf_seq_printf_btf)(struct seq_file *m, struct btf_ptr *ptr, __u32
  * Returns
  * 	The id is returned or 0 in case the id could not be retrieved.
  */
-static __u64 (*bpf_skb_cgroup_classid)(struct __sk_buff *skb) = (void *) 151;
+static __u64 (*bpf_skb_cgroup_classid)(struct __sk_buff *skb) = (void *) 152;
 
 /*
  * bpf_redirect_neigh
@@ -3618,7 +3600,7 @@ static __u64 (*bpf_skb_cgroup_classid)(struct __sk_buff *skb) = (void *) 151;
  * 	The helper returns **TC_ACT_REDIRECT** on success or
  * 	**TC_ACT_SHOT** on error.
  */
-static long (*bpf_redirect_neigh)(__u32 ifindex, struct bpf_redir_neigh *params, int plen, __u64 flags) = (void *) 152;
+static long (*bpf_redirect_neigh)(__u32 ifindex, struct bpf_redir_neigh *params, int plen, __u64 flags) = (void *) 153;
 
 /*
  * bpf_per_cpu_ptr
@@ -3639,7 +3621,7 @@ static long (*bpf_redirect_neigh)(__u32 ifindex, struct bpf_redir_neigh *params,
  * 	A pointer pointing to the kernel percpu variable on *cpu*, or
  * 	NULL, if *cpu* is invalid.
  */
-static void *(*bpf_per_cpu_ptr)(const void *percpu_ptr, __u32 cpu) = (void *) 153;
+static void *(*bpf_per_cpu_ptr)(const void *percpu_ptr, __u32 cpu) = (void *) 154;
 
 /*
  * bpf_this_cpu_ptr
@@ -3655,7 +3637,7 @@ static void *(*bpf_per_cpu_ptr)(const void *percpu_ptr, __u32 cpu) = (void *) 15
  * Returns
  * 	A pointer pointing to the kernel percpu variable on this cpu.
  */
-static void *(*bpf_this_cpu_ptr)(const void *percpu_ptr) = (void *) 154;
+static void *(*bpf_this_cpu_ptr)(const void *percpu_ptr) = (void *) 155;
 
 /*
  * bpf_redirect_peer
@@ -3675,7 +3657,7 @@ static void *(*bpf_this_cpu_ptr)(const void *percpu_ptr) = (void *) 154;
  * 	The helper returns **TC_ACT_REDIRECT** on success or
  * 	**TC_ACT_SHOT** on error.
  */
-static long (*bpf_redirect_peer)(__u32 ifindex, __u64 flags) = (void *) 155;
+static long (*bpf_redirect_peer)(__u32 ifindex, __u64 flags) = (void *) 156;
 
 /*
  * bpf_task_storage_get
@@ -3707,7 +3689,7 @@ static long (*bpf_redirect_peer)(__u32 ifindex, __u64 flags) = (void *) 155;
  * 	**NULL** if not found or there was an error in adding
  * 	a new bpf_local_storage.
  */
-static void *(*bpf_task_storage_get)(void *map, struct task_struct *task, void *value, __u64 flags) = (void *) 156;
+static void *(*bpf_task_storage_get)(void *map, struct task_struct *task, void *value, __u64 flags) = (void *) 157;
 
 /*
  * bpf_task_storage_delete
@@ -3719,7 +3701,7 @@ static void *(*bpf_task_storage_get)(void *map, struct task_struct *task, void *
  *
  * 	**-ENOENT** if the bpf_local_storage cannot be found.
  */
-static long (*bpf_task_storage_delete)(void *map, struct task_struct *task) = (void *) 157;
+static long (*bpf_task_storage_delete)(void *map, struct task_struct *task) = (void *) 158;
 
 /*
  * bpf_get_current_task_btf
@@ -3731,7 +3713,7 @@ static long (*bpf_task_storage_delete)(void *map, struct task_struct *task) = (v
  * Returns
  * 	Pointer to the current task.
  */
-static struct task_struct *(*bpf_get_current_task_btf)(void) = (void *) 158;
+static struct task_struct *(*bpf_get_current_task_btf)(void) = (void *) 159;
 
 /*
  * bpf_bprm_opts_set
@@ -3745,7 +3727,7 @@ static struct task_struct *(*bpf_get_current_task_btf)(void) = (void *) 158;
  * Returns
  * 	**-EINVAL** if invalid *flags* are passed, zero otherwise.
  */
-static long (*bpf_bprm_opts_set)(struct linux_binprm *bprm, __u64 flags) = (void *) 159;
+static long (*bpf_bprm_opts_set)(struct linux_binprm *bprm, __u64 flags) = (void *) 160;
 
 /*
  * bpf_ktime_get_coarse_ns
@@ -3759,7 +3741,7 @@ static long (*bpf_bprm_opts_set)(struct linux_binprm *bprm, __u64 flags) = (void
  * Returns
  * 	Current *ktime*.
  */
-static __u64 (*bpf_ktime_get_coarse_ns)(void) = (void *) 160;
+static __u64 (*bpf_ktime_get_coarse_ns)(void) = (void *) 161;
 
 /*
  * bpf_ima_inode_hash
@@ -3773,7 +3755,7 @@ static __u64 (*bpf_ktime_get_coarse_ns)(void) = (void *) 160;
  * 	**-EOPNOTSUP** if IMA is disabled or **-EINVAL** if
  * 	invalid arguments are passed.
  */
-static long (*bpf_ima_inode_hash)(struct inode *inode, void *dst, __u32 size) = (void *) 161;
+static long (*bpf_ima_inode_hash)(struct inode *inode, void *dst, __u32 size) = (void *) 162;
 
 /*
  * bpf_sock_from_file
@@ -3785,7 +3767,7 @@ static long (*bpf_ima_inode_hash)(struct inode *inode, void *dst, __u32 size) =
  * 	A pointer to a struct socket on success or NULL if the file is
  * 	not a socket.
  */
-static struct socket *(*bpf_sock_from_file)(struct file *file) = (void *) 162;
+static struct socket *(*bpf_sock_from_file)(struct file *file) = (void *) 163;
 
 /*
  * bpf_check_mtu
@@ -3856,7 +3838,7 @@ static struct socket *(*bpf_sock_from_file)(struct file *file) = (void *) 162;
  * 	* **BPF_MTU_CHK_RET_FRAG_NEEDED**
  * 	* **BPF_MTU_CHK_RET_SEGS_TOOBIG**
  */
-static long (*bpf_check_mtu)(void *ctx, __u32 ifindex, __u32 *mtu_len, __s32 len_diff, __u64 flags) = (void *) 163;
+static long (*bpf_check_mtu)(void *ctx, __u32 ifindex, __u32 *mtu_len, __s32 len_diff, __u64 flags) = (void *) 164;
 
 /*
  * bpf_for_each_map_elem
@@ -3889,7 +3871,7 @@ static long (*bpf_check_mtu)(void *ctx, __u32 ifindex, __u32 *mtu_len, __s32 len
  * 	The number of traversed map elements for success, **-EINVAL** for
  * 	invalid **flags**.
  */
-static long (*bpf_for_each_map_elem)(void *map, void *callback_fn, void *callback_ctx, __u64 flags) = (void *) 164;
+static long (*bpf_for_each_map_elem)(void *map, void *callback_fn, void *callback_ctx, __u64 flags) = (void *) 165;
 
 /*
  * bpf_snprintf
@@ -3901,8 +3883,7 @@ static long (*bpf_for_each_map_elem)(void *map, void *callback_fn, void *callbac
  * 	Each format specifier in **fmt** corresponds to one u64 element
  * 	in the **data** array. For strings and pointers where pointees
  * 	are accessed, only the pointer values are stored in the *data*
- * 	array. The *data_len* is the size of *data* in bytes - must be
- * 	a multiple of 8.
+ * 	array. The *data_len* is the size of *data* in bytes.
  *
  * 	Formats **%s** and **%p{i,I}{4,6}** require to read kernel
  * 	memory. Reading kernel memory may fail due to either invalid
@@ -3921,7 +3902,7 @@ static long (*bpf_for_each_map_elem)(void *map, void *callback_fn, void *callbac
  *
  * 	Or **-EBUSY** if the per-CPU memory copy buffer is busy.
  */
-static long (*bpf_snprintf)(char *str, __u32 str_size, const char *fmt, __u64 *data, __u32 data_len) = (void *) 165;
+static long (*bpf_snprintf)(char *str, __u32 str_size, const char *fmt, __u64 *data, __u32 data_len) = (void *) 166;
 
 /*
  * bpf_sys_bpf
@@ -3931,7 +3912,7 @@ static long (*bpf_snprintf)(char *str, __u32 str_size, const char *fmt, __u64 *d
  * Returns
  * 	A syscall result.
  */
-static long (*bpf_sys_bpf)(__u32 cmd, void *attr, __u32 attr_size) = (void *) 166;
+static long (*bpf_sys_bpf)(__u32 cmd, void *attr, __u32 attr_size) = (void *) 167;
 
 /*
  * bpf_btf_find_by_name_kind
@@ -3941,7 +3922,7 @@ static long (*bpf_sys_bpf)(__u32 cmd, void *attr, __u32 attr_size) = (void *) 16
  * Returns
  * 	Returns btf_id and btf_obj_fd in lower and upper 32 bits.
  */
-static long (*bpf_btf_find_by_name_kind)(char *name, int name_sz, __u32 kind, int flags) = (void *) 167;
+static long (*bpf_btf_find_by_name_kind)(char *name, int name_sz, __u32 kind, int flags) = (void *) 168;
 
 /*
  * bpf_sys_close
@@ -3951,7 +3932,7 @@ static long (*bpf_btf_find_by_name_kind)(char *name, int name_sz, __u32 kind, in
  * Returns
  * 	A syscall result.
  */
-static long (*bpf_sys_close)(__u32 fd) = (void *) 168;
+static long (*bpf_sys_close)(__u32 fd) = (void *) 169;
 
 /*
  * bpf_timer_init
@@ -3972,7 +3953,7 @@ static long (*bpf_sys_close)(__u32 fd) = (void *) 168;
  * 	or pin such map in bpffs. When map is unpinned or file descriptor is
  * 	closed all timers in the map will be cancelled and freed.
  */
-static long (*bpf_timer_init)(struct bpf_timer *timer, void *map, __u64 flags) = (void *) 169;
+static long (*bpf_timer_init)(struct bpf_timer *timer, void *map, __u64 flags) = (void *) 170;
 
 /*
  * bpf_timer_set_callback
@@ -3987,7 +3968,7 @@ static long (*bpf_timer_init)(struct bpf_timer *timer, void *map, __u64 flags) =
  * 	or pin such map in bpffs. When map is unpinned or file descriptor is
  * 	closed all timers in the map will be cancelled and freed.
  */
-static long (*bpf_timer_set_callback)(struct bpf_timer *timer, void *callback_fn) = (void *) 170;
+static long (*bpf_timer_set_callback)(struct bpf_timer *timer, void *callback_fn) = (void *) 171;
 
 /*
  * bpf_timer_start
@@ -4017,7 +3998,7 @@ static long (*bpf_timer_set_callback)(struct bpf_timer *timer, void *callback_fn
  * 	**-EINVAL** if *timer* was not initialized with bpf_timer_init() earlier
  * 	or invalid *flags* are passed.
  */
-static long (*bpf_timer_start)(struct bpf_timer *timer, __u64 nsecs, __u64 flags) = (void *) 171;
+static long (*bpf_timer_start)(struct bpf_timer *timer, __u64 nsecs, __u64 flags) = (void *) 172;
 
 /*
  * bpf_timer_cancel
@@ -4031,7 +4012,7 @@ static long (*bpf_timer_start)(struct bpf_timer *timer, __u64 nsecs, __u64 flags
  * 	**-EDEADLK** if callback_fn tried to call bpf_timer_cancel() on its
  * 	own timer which would have led to a deadlock otherwise.
  */
-static long (*bpf_timer_cancel)(struct bpf_timer *timer) = (void *) 172;
+static long (*bpf_timer_cancel)(struct bpf_timer *timer) = (void *) 173;
 
 /*
  * bpf_get_func_ip
@@ -4041,7 +4022,7 @@ static long (*bpf_timer_cancel)(struct bpf_timer *timer) = (void *) 172;
  * Returns
  * 	Address of the traced function.
  */
-static __u64 (*bpf_get_func_ip)(void *ctx) = (void *) 173;
+static __u64 (*bpf_get_func_ip)(void *ctx) = (void *) 174;
 
 /*
  * bpf_get_attach_cookie
@@ -4060,7 +4041,7 @@ static __u64 (*bpf_get_func_ip)(void *ctx) = (void *) 173;
  * 	Value specified by user at BPF link creation/attachment time
  * 	or 0, if it was not specified.
  */
-static __u64 (*bpf_get_attach_cookie)(void *ctx) = (void *) 174;
+static __u64 (*bpf_get_attach_cookie)(void *ctx) = (void *) 175;
 
 /*
  * bpf_task_pt_regs
@@ -4070,540 +4051,6 @@ static __u64 (*bpf_get_attach_cookie)(void *ctx) = (void *) 174;
  * Returns
  * 	A pointer to struct pt_regs.
  */
-static long (*bpf_task_pt_regs)(struct task_struct *task) = (void *) 175;
-
-/*
- * bpf_get_branch_snapshot
- *
- * 	Get branch trace from hardware engines like Intel LBR. The
- * 	hardware engine is stopped shortly after the helper is
- * 	called. Therefore, the user need to filter branch entries
- * 	based on the actual use case. To capture branch trace
- * 	before the trigger point of the BPF program, the helper
- * 	should be called at the beginning of the BPF program.
- *
- * 	The data is stored as struct perf_branch_entry into output
- * 	buffer *entries*. *size* is the size of *entries* in bytes.
- * 	*flags* is reserved for now and must be zero.
- *
- *
- * Returns
- * 	On success, number of bytes written to *buf*. On error, a
- * 	negative value.
- *
- * 	**-EINVAL** if *flags* is not zero.
- *
- * 	**-ENOENT** if architecture does not support branch records.
- */
-static long (*bpf_get_branch_snapshot)(void *entries, __u32 size, __u64 flags) = (void *) 176;
-
-/*
- * bpf_trace_vprintk
- *
- * 	Behaves like **bpf_trace_printk**\ () helper, but takes an array of u64
- * 	to format and can handle more format args as a result.
- *
- * 	Arguments are to be used as in **bpf_seq_printf**\ () helper.
- *
- * Returns
- * 	The number of bytes written to the buffer, or a negative error
- * 	in case of failure.
- */
-static long (*bpf_trace_vprintk)(const char *fmt, __u32 fmt_size, const void *data, __u32 data_len) = (void *) 177;
-
-/*
- * bpf_skc_to_unix_sock
- *
- * 	Dynamically cast a *sk* pointer to a *unix_sock* pointer.
- *
- * Returns
- * 	*sk* if casting is valid, or **NULL** otherwise.
- */
-static struct unix_sock *(*bpf_skc_to_unix_sock)(void *sk) = (void *) 178;
-
-/*
- * bpf_kallsyms_lookup_name
- *
- * 	Get the address of a kernel symbol, returned in *res*. *res* is
- * 	set to 0 if the symbol is not found.
- *
- * Returns
- * 	On success, zero. On error, a negative value.
- *
- * 	**-EINVAL** if *flags* is not zero.
- *
- * 	**-EINVAL** if string *name* is not the same size as *name_sz*.
- *
- * 	**-ENOENT** if symbol is not found.
- *
- * 	**-EPERM** if caller does not have permission to obtain kernel address.
- */
-static long (*bpf_kallsyms_lookup_name)(const char *name, int name_sz, int flags, __u64 *res) = (void *) 179;
-
-/*
- * bpf_find_vma
- *
- * 	Find vma of *task* that contains *addr*, call *callback_fn*
- * 	function with *task*, *vma*, and *callback_ctx*.
- * 	The *callback_fn* should be a static function and
- * 	the *callback_ctx* should be a pointer to the stack.
- * 	The *flags* is used to control certain aspects of the helper.
- * 	Currently, the *flags* must be 0.
- *
- * 	The expected callback signature is
- *
- * 	long (\*callback_fn)(struct task_struct \*task, struct vm_area_struct \*vma, void \*callback_ctx);
- *
- *
- * Returns
- * 	0 on success.
- * 	**-ENOENT** if *task->mm* is NULL, or no vma contains *addr*.
- * 	**-EBUSY** if failed to try lock mmap_lock.
- * 	**-EINVAL** for invalid **flags**.
- */
-static long (*bpf_find_vma)(struct task_struct *task, __u64 addr, void *callback_fn, void *callback_ctx, __u64 flags) = (void *) 180;
-
-/*
- * bpf_loop
- *
- * 	For **nr_loops**, call **callback_fn** function
- * 	with **callback_ctx** as the context parameter.
- * 	The **callback_fn** should be a static function and
- * 	the **callback_ctx** should be a pointer to the stack.
- * 	The **flags** is used to control certain aspects of the helper.
- * 	Currently, the **flags** must be 0. Currently, nr_loops is
- * 	limited to 1 << 23 (~8 million) loops.
- *
- * 	long (\*callback_fn)(u32 index, void \*ctx);
- *
- * 	where **index** is the current index in the loop. The index
- * 	is zero-indexed.
- *
- * 	If **callback_fn** returns 0, the helper will continue to the next
- * 	loop. If return value is 1, the helper will skip the rest of
- * 	the loops and return. Other return values are not used now,
- * 	and will be rejected by the verifier.
- *
- *
- * Returns
- * 	The number of loops performed, **-EINVAL** for invalid **flags**,
- * 	**-E2BIG** if **nr_loops** exceeds the maximum number of loops.
- */
-static long (*bpf_loop)(__u32 nr_loops, void *callback_fn, void *callback_ctx, __u64 flags) = (void *) 181;
-
-/*
- * bpf_strncmp
- *
- * 	Do strncmp() between **s1** and **s2**. **s1** doesn't need
- * 	to be null-terminated and **s1_sz** is the maximum storage
- * 	size of **s1**. **s2** must be a read-only string.
- *
- * Returns
- * 	An integer less than, equal to, or greater than zero
- * 	if the first **s1_sz** bytes of **s1** is found to be
- * 	less than, to match, or be greater than **s2**.
- */
-static long (*bpf_strncmp)(const char *s1, __u32 s1_sz, const char *s2) = (void *) 182;
-
-/*
- * bpf_get_func_arg
- *
- * 	Get **n**-th argument (zero based) of the traced function (for tracing programs)
- * 	returned in **value**.
- *
- *
- * Returns
- * 	0 on success.
- * 	**-EINVAL** if n >= arguments count of traced function.
- */
-static long (*bpf_get_func_arg)(void *ctx, __u32 n, __u64 *value) = (void *) 183;
-
-/*
- * bpf_get_func_ret
- *
- * 	Get return value of the traced function (for tracing programs)
- * 	in **value**.
- *
- *
- * Returns
- * 	0 on success.
- * 	**-EOPNOTSUPP** for tracing programs other than BPF_TRACE_FEXIT or BPF_MODIFY_RETURN.
- */
-static long (*bpf_get_func_ret)(void *ctx, __u64 *value) = (void *) 184;
-
-/*
- * bpf_get_func_arg_cnt
- *
- * 	Get number of arguments of the traced function (for tracing programs).
- *
- *
- * Returns
- * 	The number of arguments of the traced function.
- */
-static long (*bpf_get_func_arg_cnt)(void *ctx) = (void *) 185;
-
-/*
- * bpf_get_retval
- *
- * 	Get the syscall's return value that will be returned to userspace.
- *
- * 	This helper is currently supported by cgroup programs only.
- *
- * Returns
- * 	The syscall's return value.
- */
-static int (*bpf_get_retval)(void) = (void *) 186;
-
-/*
- * bpf_set_retval
- *
- * 	Set the syscall's return value that will be returned to userspace.
- *
- * 	This helper is currently supported by cgroup programs only.
- *
- * Returns
- * 	0 on success, or a negative error in case of failure.
- */
-static int (*bpf_set_retval)(int retval) = (void *) 187;
-
-/*
- * bpf_xdp_get_buff_len
- *
- * 	Get the total size of a given xdp buff (linear and paged area)
- *
- * Returns
- * 	The total size of a given xdp buffer.
- */
-static __u64 (*bpf_xdp_get_buff_len)(struct xdp_md *xdp_md) = (void *) 188;
-
-/*
- * bpf_xdp_load_bytes
- *
- * 	This helper is provided as an easy way to load data from a
- * 	xdp buffer. It can be used to load *len* bytes from *offset* from
- * 	the frame associated to *xdp_md*, into the buffer pointed by
- * 	*buf*.
- *
- * Returns
- * 	0 on success, or a negative error in case of failure.
- */
-static long (*bpf_xdp_load_bytes)(struct xdp_md *xdp_md, __u32 offset, void *buf, __u32 len) = (void *) 189;
-
-/*
- * bpf_xdp_store_bytes
- *
- * 	Store *len* bytes from buffer *buf* into the frame
- * 	associated to *xdp_md*, at *offset*.
- *
- * Returns
- * 	0 on success, or a negative error in case of failure.
- */
-static long (*bpf_xdp_store_bytes)(struct xdp_md *xdp_md, __u32 offset, void *buf, __u32 len) = (void *) 190;
-
-/*
- * bpf_copy_from_user_task
- *
- * 	Read *size* bytes from user space address *user_ptr* in *tsk*'s
- * 	address space, and stores the data in *dst*. *flags* is not
- * 	used yet and is provided for future extensibility. This helper
- * 	can only be used by sleepable programs.
- *
- * Returns
- * 	0 on success, or a negative error in case of failure. On error
- * 	*dst* buffer is zeroed out.
- */
-static long (*bpf_copy_from_user_task)(void *dst, __u32 size, const void *user_ptr, struct task_struct *tsk, __u64 flags) = (void *) 191;
-
-/*
- * bpf_skb_set_tstamp
- *
- * 	Change the __sk_buff->tstamp_type to *tstamp_type*
- * 	and set *tstamp* to the __sk_buff->tstamp together.
- *
- * 	If there is no need to change the __sk_buff->tstamp_type,
- * 	the tstamp value can be directly written to __sk_buff->tstamp
- * 	instead.
- *
- * 	BPF_SKB_TSTAMP_DELIVERY_MONO is the only tstamp that
- * 	will be kept during bpf_redirect_*().  A non zero
- * 	*tstamp* must be used with the BPF_SKB_TSTAMP_DELIVERY_MONO
- * 	*tstamp_type*.
- *
- * 	A BPF_SKB_TSTAMP_UNSPEC *tstamp_type* can only be used
- * 	with a zero *tstamp*.
- *
- * 	Only IPv4 and IPv6 skb->protocol are supported.
- *
- * 	This function is most useful when it needs to set a
- * 	mono delivery time to __sk_buff->tstamp and then
- * 	bpf_redirect_*() to the egress of an iface.  For example,
- * 	changing the (rcv) timestamp in __sk_buff->tstamp at
- * 	ingress to a mono delivery time and then bpf_redirect_*()
- * 	to sch_fq@phy-dev.
- *
- * Returns
- * 	0 on success.
- * 	**-EINVAL** for invalid input
- * 	**-EOPNOTSUPP** for unsupported protocol
- */
-static long (*bpf_skb_set_tstamp)(struct __sk_buff *skb, __u64 tstamp, __u32 tstamp_type) = (void *) 192;
-
-/*
- * bpf_ima_file_hash
- *
- * 	Returns a calculated IMA hash of the *file*.
- * 	If the hash is larger than *size*, then only *size*
- * 	bytes will be copied to *dst*
- *
- * Returns
- * 	The **hash_algo** is returned on success,
- * 	**-EOPNOTSUP** if the hash calculation failed or **-EINVAL** if
- * 	invalid arguments are passed.
- */
-static long (*bpf_ima_file_hash)(struct file *file, void *dst, __u32 size) = (void *) 193;
-
-/*
- * bpf_kptr_xchg
- *
- * 	Exchange kptr at pointer *map_value* with *ptr*, and return the
- * 	old value. *ptr* can be NULL, otherwise it must be a referenced
- * 	pointer which will be released when this helper is called.
- *
- * Returns
- * 	The old value of kptr (which can be NULL). The returned pointer
- * 	if not NULL, is a reference which must be released using its
- * 	corresponding release function, or moved into a BPF map before
- * 	program exit.
- */
-static void *(*bpf_kptr_xchg)(void *map_value, void *ptr) = (void *) 194;
-
-/*
- * bpf_map_lookup_percpu_elem
- *
- * 	Perform a lookup in *percpu map* for an entry associated to
- * 	*key* on *cpu*.
- *
- * Returns
- * 	Map value associated to *key* on *cpu*, or **NULL** if no entry
- * 	was found or *cpu* is invalid.
- */
-static void *(*bpf_map_lookup_percpu_elem)(void *map, const void *key, __u32 cpu) = (void *) 195;
-
-/*
- * bpf_skc_to_mptcp_sock
- *
- * 	Dynamically cast a *sk* pointer to a *mptcp_sock* pointer.
- *
- * Returns
- * 	*sk* if casting is valid, or **NULL** otherwise.
- */
-static struct mptcp_sock *(*bpf_skc_to_mptcp_sock)(void *sk) = (void *) 196;
-
-/*
- * bpf_dynptr_from_mem
- *
- * 	Get a dynptr to local memory *data*.
- *
- * 	*data* must be a ptr to a map value.
- * 	The maximum *size* supported is DYNPTR_MAX_SIZE.
- * 	*flags* is currently unused.
- *
- * Returns
- * 	0 on success, -E2BIG if the size exceeds DYNPTR_MAX_SIZE,
- * 	-EINVAL if flags is not 0.
- */
-static long (*bpf_dynptr_from_mem)(void *data, __u32 size, __u64 flags, struct bpf_dynptr *ptr) = (void *) 197;
-
-/*
- * bpf_ringbuf_reserve_dynptr
- *
- * 	Reserve *size* bytes of payload in a ring buffer *ringbuf*
- * 	through the dynptr interface. *flags* must be 0.
- *
- * 	Please note that a corresponding bpf_ringbuf_submit_dynptr or
- * 	bpf_ringbuf_discard_dynptr must be called on *ptr*, even if the
- * 	reservation fails. This is enforced by the verifier.
- *
- * Returns
- * 	0 on success, or a negative error in case of failure.
- */
-static long (*bpf_ringbuf_reserve_dynptr)(void *ringbuf, __u32 size, __u64 flags, struct bpf_dynptr *ptr) = (void *) 198;
-
-/*
- * bpf_ringbuf_submit_dynptr
- *
- * 	Submit reserved ring buffer sample, pointed to by *data*,
- * 	through the dynptr interface. This is a no-op if the dynptr is
- * 	invalid/null.
- *
- * 	For more information on *flags*, please see
- * 	'bpf_ringbuf_submit'.
- *
- * Returns
- * 	Nothing. Always succeeds.
- */
-static void (*bpf_ringbuf_submit_dynptr)(struct bpf_dynptr *ptr, __u64 flags) = (void *) 199;
-
-/*
- * bpf_ringbuf_discard_dynptr
- *
- * 	Discard reserved ring buffer sample through the dynptr
- * 	interface. This is a no-op if the dynptr is invalid/null.
- *
- * 	For more information on *flags*, please see
- * 	'bpf_ringbuf_discard'.
- *
- * Returns
- * 	Nothing. Always succeeds.
- */
-static void (*bpf_ringbuf_discard_dynptr)(struct bpf_dynptr *ptr, __u64 flags) = (void *) 200;
-
-/*
- * bpf_dynptr_read
- *
- * 	Read *len* bytes from *src* into *dst*, starting from *offset*
- * 	into *src*.
- * 	*flags* is currently unused.
- *
- * Returns
- * 	0 on success, -E2BIG if *offset* + *len* exceeds the length
- * 	of *src*'s data, -EINVAL if *src* is an invalid dynptr or if
- * 	*flags* is not 0.
- */
-static long (*bpf_dynptr_read)(void *dst, __u32 len, struct bpf_dynptr *src, __u32 offset, __u64 flags) = (void *) 201;
-
-/*
- * bpf_dynptr_write
- *
- * 	Write *len* bytes from *src* into *dst*, starting from *offset*
- * 	into *dst*.
- * 	*flags* is currently unused.
- *
- * Returns
- * 	0 on success, -E2BIG if *offset* + *len* exceeds the length
- * 	of *dst*'s data, -EINVAL if *dst* is an invalid dynptr or if *dst*
- * 	is a read-only dynptr or if *flags* is not 0.
- */
-static long (*bpf_dynptr_write)(struct bpf_dynptr *dst, __u32 offset, void *src, __u32 len, __u64 flags) = (void *) 202;
-
-/*
- * bpf_dynptr_data
- *
- * 	Get a pointer to the underlying dynptr data.
- *
- * 	*len* must be a statically known value. The returned data slice
- * 	is invalidated whenever the dynptr is invalidated.
- *
- * Returns
- * 	Pointer to the underlying dynptr data, NULL if the dynptr is
- * 	read-only, if the dynptr is invalid, or if the offset and length
- * 	is out of bounds.
- */
-static void *(*bpf_dynptr_data)(struct bpf_dynptr *ptr, __u32 offset, __u32 len) = (void *) 203;
-
-/*
- * bpf_tcp_raw_gen_syncookie_ipv4
- *
- * 	Try to issue a SYN cookie for the packet with corresponding
- * 	IPv4/TCP headers, *iph* and *th*, without depending on a
- * 	listening socket.
- *
- * 	*iph* points to the IPv4 header.
- *
- * 	*th* points to the start of the TCP header, while *th_len*
- * 	contains the length of the TCP header (at least
- * 	**sizeof**\ (**struct tcphdr**)).
- *
- * Returns
- * 	On success, lower 32 bits hold the generated SYN cookie in
- * 	followed by 16 bits which hold the MSS value for that cookie,
- * 	and the top 16 bits are unused.
- *
- * 	On failure, the returned value is one of the following:
- *
- * 	**-EINVAL** if *th_len* is invalid.
- */
-static __s64 (*bpf_tcp_raw_gen_syncookie_ipv4)(struct iphdr *iph, struct tcphdr *th, __u32 th_len) = (void *) 204;
-
-/*
- * bpf_tcp_raw_gen_syncookie_ipv6
- *
- * 	Try to issue a SYN cookie for the packet with corresponding
- * 	IPv6/TCP headers, *iph* and *th*, without depending on a
- * 	listening socket.
- *
- * 	*iph* points to the IPv6 header.
- *
- * 	*th* points to the start of the TCP header, while *th_len*
- * 	contains the length of the TCP header (at least
- * 	**sizeof**\ (**struct tcphdr**)).
- *
- * Returns
- * 	On success, lower 32 bits hold the generated SYN cookie in
- * 	followed by 16 bits which hold the MSS value for that cookie,
- * 	and the top 16 bits are unused.
- *
- * 	On failure, the returned value is one of the following:
- *
- * 	**-EINVAL** if *th_len* is invalid.
- *
- * 	**-EPROTONOSUPPORT** if CONFIG_IPV6 is not builtin.
- */
-static __s64 (*bpf_tcp_raw_gen_syncookie_ipv6)(struct ipv6hdr *iph, struct tcphdr *th, __u32 th_len) = (void *) 205;
-
-/*
- * bpf_tcp_raw_check_syncookie_ipv4
- *
- * 	Check whether *iph* and *th* contain a valid SYN cookie ACK
- * 	without depending on a listening socket.
- *
- * 	*iph* points to the IPv4 header.
- *
- * 	*th* points to the TCP header.
- *
- * Returns
- * 	0 if *iph* and *th* are a valid SYN cookie ACK.
- *
- * 	On failure, the returned value is one of the following:
- *
- * 	**-EACCES** if the SYN cookie is not valid.
- */
-static long (*bpf_tcp_raw_check_syncookie_ipv4)(struct iphdr *iph, struct tcphdr *th) = (void *) 206;
-
-/*
- * bpf_tcp_raw_check_syncookie_ipv6
- *
- * 	Check whether *iph* and *th* contain a valid SYN cookie ACK
- * 	without depending on a listening socket.
- *
- * 	*iph* points to the IPv6 header.
- *
- * 	*th* points to the TCP header.
- *
- * Returns
- * 	0 if *iph* and *th* are a valid SYN cookie ACK.
- *
- * 	On failure, the returned value is one of the following:
- *
- * 	**-EACCES** if the SYN cookie is not valid.
- *
- * 	**-EPROTONOSUPPORT** if CONFIG_IPV6 is not builtin.
- */
-static long (*bpf_tcp_raw_check_syncookie_ipv6)(struct ipv6hdr *iph, struct tcphdr *th) = (void *) 207;
-
-/*
- * bpf_ktime_get_tai_ns
- *
- * 	A nonsettable system-wide clock derived from wall-clock time but
- * 	ignoring leap seconds.  This clock does not experience
- * 	discontinuities and backwards jumps caused by NTP inserting leap
- * 	seconds as CLOCK_REALTIME does.
- *
- * 	See: **clock_gettime**\ (**CLOCK_TAI**)
- *
- * Returns
- * 	Current *ktime*.
- */
-static __u64 (*bpf_ktime_get_tai_ns)(void) = (void *) 208;
+static long (*bpf_task_pt_regs)(struct task_struct *task) = (void *) 176;
 
 
